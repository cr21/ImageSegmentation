{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZEe2gxXB+QzDO9Qk77gRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cr21/ImageSegmentation/blob/main/U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74QnivW5w6cN",
        "outputId": "25cfbc82-04d2-4639-f64c-7eaadcad8d64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ao7FZqxNMI"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Dataset/TrafficData/')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp4j-xx_xQC9"
      },
      "source": [
        "# Math functions\n",
        "# https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
        "import math\n",
        "# Image related function from python image library\n",
        "from PIL import Image, ImageDraw\n",
        "from PIL import ImagePath\n",
        "# pandas for data processing\n",
        "import pandas as pd\n",
        "# operating system api\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "# to monitor progress of iteration\n",
        "from tqdm import tqdm\n",
        "# json data processing\n",
        "import json\n",
        "# opencv library version 2\n",
        "import cv2\n",
        "# numpy for numerical processing of tensor\n",
        "import numpy as np\n",
        "# plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "# urllib to get data from url\n",
        "import urllib\n",
        "pd.options.display.max_colwidth =1000\n",
        "# tensor flow \n",
        "import tensorflow as tf\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# from hilbert import hilbertCurve\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "from tensorflow.keras.layers import Flatten\n",
        "# split train and test data\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-8o41SWxOKB"
      },
      "source": [
        "# https://www.jeremyjordan.me/semantic-segmentation/#advanced_unet"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlnFKHfyjBk8",
        "outputId": "e90f4107-57e4-4fcf-fab1-6af7fd7840c1"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/        preprocessed_data.csv     uniquelabels.txt\n",
            "data_df.csv  preprocessed_data.gsheet  uniqueLabels.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XaA28sH9jO-c",
        "outputId": "8979959b-1739-4f45-cbdd-8c1f7a8f8566"
      },
      "source": [
        "#  get preprocessed Images\n",
        "preprocessed_data = pd.read_csv(\"preprocessed_data.csv\")\n",
        "preprocessed_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>json</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/images/201/frame0029_leftImg8bit.jpg</td>\n",
              "      <td>data/mask/201/frame0029_gtFine_polygons.json</td>\n",
              "      <td>data/output/201/frame0029_gtFine_polygons.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/images/201/frame0299_leftImg8bit.jpg</td>\n",
              "      <td>data/mask/201/frame0299_gtFine_polygons.json</td>\n",
              "      <td>data/output/201/frame0299_gtFine_polygons.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/images/201/frame0779_leftImg8bit.jpg</td>\n",
              "      <td>data/mask/201/frame0779_gtFine_polygons.json</td>\n",
              "      <td>data/output/201/frame0779_gtFine_polygons.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/images/201/frame1019_leftImg8bit.jpg</td>\n",
              "      <td>data/mask/201/frame1019_gtFine_polygons.json</td>\n",
              "      <td>data/output/201/frame1019_gtFine_polygons.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/images/201/frame1469_leftImg8bit.jpg</td>\n",
              "      <td>data/mask/201/frame1469_gtFine_polygons.json</td>\n",
              "      <td>data/output/201/frame1469_gtFine_polygons.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       image  ...                                           mask\n",
              "0  data/images/201/frame0029_leftImg8bit.jpg  ...  data/output/201/frame0029_gtFine_polygons.png\n",
              "1  data/images/201/frame0299_leftImg8bit.jpg  ...  data/output/201/frame0299_gtFine_polygons.png\n",
              "2  data/images/201/frame0779_leftImg8bit.jpg  ...  data/output/201/frame0779_gtFine_polygons.png\n",
              "3  data/images/201/frame1019_leftImg8bit.jpg  ...  data/output/201/frame1019_gtFine_polygons.png\n",
              "4  data/images/201/frame1469_leftImg8bit.jpg  ...  data/output/201/frame1469_gtFine_polygons.png\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltwI2eg8jaaL"
      },
      "source": [
        "X_train, X_test = train_test_split(preprocessed_data, test_size=0.20, random_state=21)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5LwqrpHpUQy",
        "outputId": "9e4c91cb-a355-4ae3-bf91-5ba3e9b330ed"
      },
      "source": [
        "print(f\"X_train Data shape {X_train.shape}\")\n",
        "print(f\"X_test Data shape {X_test.shape}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Data shape (3206, 3)\n",
            "X_test Data shape (802, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG9C5LNCsKZQ"
      },
      "source": [
        "label_clr = {'road':10, 'parking':20, 'drivable fallback':20,'sidewalk':30,'non-drivable fallback':40,'rail track':40,\\\n",
        "                        'person':50, 'animal':50, 'rider':60, 'motorcycle':70, 'bicycle':70, 'autorickshaw':80,\\\n",
        "                        'car':80, 'truck':90, 'bus':90, 'vehicle fallback':90, 'trailer':90, 'caravan':90,\\\n",
        "                        'curb':100, 'wall':100, 'fence':110,'guard rail':110, 'billboard':120,'traffic sign':120,\\\n",
        "                        'traffic light':120, 'pole':130, 'polegroup':130, 'obs-str-bar-fallback':130,'building':140,\\\n",
        "                        'bridge':140,'tunnel':140, 'vegetation':150, 'sky':160, 'fallback background':160,'unlabeled':0,\\\n",
        "                        'out of roi':0, 'ego vehicle':170, 'ground':180,'rectification border':190,\\\n",
        "                   'train':200}\n",
        "classes = list(set([filler for filler in label_clr.values()]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1MrE6O4uFfO"
      },
      "source": [
        "def normalize_image(mask):\n",
        "    mask = mask/255\n",
        "    return mask"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddeaC5w-pVUR"
      },
      "source": [
        "class Dataset:\n",
        "\n",
        "    \"\"\"\n",
        "      Dataset class This class is useful for data preprocessing and getting items for Data Loader\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self, data_frame, width, height, classes):\n",
        "        \"\"\"\n",
        "          Initialize the instance variable of class.\n",
        "\n",
        "          Parameters : \n",
        "                data_frame  pandas.DataFrame -> columns : [\"Image\",\"Json\",\"mask\"]\n",
        "                width   width of input image\n",
        "                height  height of input image\n",
        "                classes : number of output channels we have in our problem and corosponding filler value \n",
        "              \n",
        "        \"\"\"\n",
        "        \n",
        "        self.width  = width\n",
        "        self.height = height\n",
        "        self.imagePath = list(data_frame[\"image\"])\n",
        "        self.maskPath = list(data_frame[\"mask\"])\n",
        "        self.classValues = classes\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "      \"\"\"\n",
        "      Function to get image and output mask at perticular index\n",
        "      we can also use any augmentation technique here\n",
        "\n",
        "      Parameters:\n",
        "        index (int) : index to fetch the data\n",
        "\n",
        "      return (image, mask) tuple\n",
        "\n",
        "      \"\"\"\n",
        "      # get and read image at index in image path\n",
        "      image = cv2.imread(self.imagePath[index],cv2.IMREAD_UNCHANGED)\n",
        "      # resize the image to match with input dimension\n",
        "      image = cv2.resize(image, (self.width, self.height), interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "      # get and read mask at index in mask path\n",
        "      mask = cv2.imread(self.maskPath[index], cv2.IMREAD_UNCHANGED)\n",
        "      # resize the mask to match with dimension\n",
        "      mask  = cv2.resize(mask, (self.width, self.height), interpolation  = cv2.INTER_NEAREST)\n",
        "      #  we have21 different objects so output channel will be 21\n",
        "      # https://www.jeremyjordan.me/semantic-segmentation/#advanced_unet\n",
        "      image_mask_with_outputchannel = [(mask == j) for j in self.classValues]\n",
        "      image_mask_with_outputchannel = np.stack(image_mask_with_outputchannel, axis = -1).astype('float')\n",
        "      \n",
        "      # Augmentation examples code might not be perfect but you could do something similar\n",
        "      #     a = np.random.uniform()\n",
        "      #     if a<0.2:\n",
        "      #         image = image\n",
        "      #         image_mask = image_mask\n",
        "      #     elif a<0.4:\n",
        "      #         image = aug3.augment_image(image)\n",
        "      #         image_mask = aug3.augment_image(image_mask)\n",
        "      #     elif a<0.6:\n",
        "      #         image = aug4.augment_image(image)\n",
        "      #         image_mask = aug4.augment_image(image_mask)\n",
        "      #     elif a<0.8:\n",
        "      #         image = aug5.augment_image(image)\n",
        "      #         image_mask = image_mask\n",
        "      #     else:\n",
        "      #         image = aug6.augment_image(image)\n",
        "      #         image_mask = aug6.augment_image(image_mask)\n",
        "              \n",
        "      return image, image_mask_with_outputchannel\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imagePath)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMZKKJpQ27Re"
      },
      "source": [
        "class DataLoader(tf.keras.utils.Sequence):\n",
        "  \"\"\"\n",
        "    Data Loader class to generate Batch from Dataset. This class implements tf.keras.utils.sequence instances\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataset, batch_size = 1, shuffle = False):\n",
        "    \"\"\"\n",
        "      initialize the parameters for the class.\n",
        "\n",
        "      parameters :\n",
        "        \n",
        "        dataset : Entire Dataset\n",
        "        batch_size = size of the batch we want to return\n",
        "        shuffle : if True shuffle the data at the end of each epoch\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.indices = np.arange(len(dataset))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    \n",
        "      Function to get the batch at index idx.\n",
        "      This will get next avaialbel batch_size set of records\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # generate the batch data\n",
        "    # get the next start and End index\n",
        "    startIndex = idx * self.batch_size\n",
        "    endIndex = (idx +1)  * self.batch_size\n",
        "    \n",
        "    collection  = []\n",
        "    #  get the  next batch from start to end index\n",
        "    for j in range(startIndex, endIndex):\n",
        "      collection.append(self.dataset[j])\n",
        "    \n",
        "      #  create a batch by appending ( original Image :( 1920 * 1080 * 3 ), Mask : (1920,1080,21))\n",
        "      #   [\n",
        "      #         ( (1920,1080,3), (1920,1080,21) )\n",
        "      #         ( (1920,1080,3), (1920,1080,21) )\n",
        "      #         ( (1920,1080,3), (1920,1080,21) )\n",
        "      #         ( (1920,1080,3), (1920,1080,21) )\n",
        "      # ]\n",
        "      \n",
        "      \n",
        "    batch = [np.stack(samples, axis=0) for samples in zip(*collection)]\n",
        "      \n",
        "    return tuple(batch)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "      Get the number of Batch : total number of batch in entire dataset\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return len(self.indices) // self.batch_size\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    \"\"\"\n",
        "      Operation to perform at the end of each epoch\n",
        "\n",
        "      We will shuffle the indices at the end of each epoch\n",
        "\n",
        "    \"\"\"\n",
        "    if self.shuffle:\n",
        "        self.indices = np.random.permutation(self.indices)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSfPU-SQLo5"
      },
      "source": [
        "train_dataset = Dataset(X_train, 1920, 1080, classes)\n",
        "test_dataset = Dataset(X_test, 1920, 1080, classes)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK6pCcKoQuPE"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset,  batch_size = 8, shuffle = True)"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}